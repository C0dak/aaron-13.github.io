# 监控方案

------

**集群健康状态监控**

```
curl -XGET 127.0.0.1:9200/_cluster/health?pretty
{
	"cluster_name" : "es1003",
  	"status" : "green",
  	"timed_out" : false,
	"number_of_nodes" : 38,
	"number_of_data_nodes" : 27,
	"active_primary_shards" : 1332,
	"active_shards" : 2381,
	"relocating_shards" : 0,
	"initializing_shards" : 0,
	"unassigned_shards" : 0,
	"number_of_pending_tasks" : 0
	"delayed_unassigned_shards" : 0,
	"number_of_in_flight_fetch" : 0,
	"task_max_waiting_in_queue_millis" : 0,
	"active_shards_percent_as_number" : 100.0tus"
}
```

**状态信息**
status:
+ green 所有分片都正确运行，集群健康

+ yellow 主分片都正确运行，副本分片缺失，kibana4在黄灯状态下也拒绝启动

+ red 有主分片缺失，这部分数据不可用


**其他数据解释**

+ number_of_nodes 集群总节点数

+ number_of_data_nodes 集群总数据节点数

+ active_primary_shards	集群搜有索引主分片总数

+ active_shards 集群所有索引分片总数

+ relocating_shards 正在迁移中的分片数

+ initializing_shards 正在初始化的分片数

+ unassigned_shards 未分配到具体节点上的分片数

+ delayed_unassigned_shards 延时呆分配到具体节点上的分片数


**level请求参数**
接口请求的时候，附件一个level参数，指定输出信息以indices还是shards级别显示
```
curl -XGET http://127.0.0.1:9200/_cluster/health?level=indices
```



## 节点状态监控接口

```
curl -XGET 127.0.0.1:9200/_nodes/stats
```


**节点概要**

```
{
   "cluster_name": "elasticsearch_zach",
   "nodes": {
      "UNr6ZMf5Qk-YCPA_L18BOQ": {
         "timestamp": 1477886018477,
         "name": "Zach",
         "transport_address": "192.168.1.131:9300",
         "host": "192.168.1.131",
         "ip": "192.168.1.131:9300",
         "roles": [
             "master",
             "data",
             "ingest"
         ],
...
```

**索引信息**

```
    "indices": {
        "docs": {
           "count": 6163666,
           "deleted": 0
        },
        "store": {
           "size_in_bytes": 2301398179,
           "throttle_time_in_millis": 122850
        },
```

docs.count是节点上存储的数据条目总数；store.size_in_bytes是节点上存储的数据占用磁盘的实际大小，而store.throttle_time_in_millis则是ES进程在做segment merge时出现磁盘限速的时长，


1. 写入性能
```
        "indexing": {
           "index_total": 803441,
           "index_time_in_millis": 367654,
           "index_current": 99,
           "delete_total": 0,
           "delete_time_in_millis": 0,
           "delete_current": 0
           "noop_update_total" : 0,
           "is_throttled" : false,
           "throttle_time_in_millis" : 0
        },
```

indexing.index_total是一个递增累计数，表示节点完成的数据写入总次数，后面删除了多少，额外记录在indexing.delete_total里，indexing.is_throttled是2.0版本后新增的计数，因为Elasticsearch从此开始自动管理throttle

1. 读取性能:
```
        "get": {
           "total": 6,
           "time_in_millis": 2,
           "exists_total": 5,
           "exists_time_in_millis": 2,
           "missing_total": 1,
           "missing_time_in_millis": 0,
           "current": 0
        },
```

1. 搜索性能
```
        "search": {
           "open_contexts": 0,
           "query_total": 123,
           "query_time_in_millis": 531,
           "query_current": 0,
           "fetch_total": 3,
           "fetch_time_in_millis": 55,
           "fetch_current": 0
           "scroll_total" : 0,
           "scroll_time_in_millis" : 0,
           "scroll_current" : 0,
           "suggest_total" : 0,
           "suggest_time_in_millis" : 0,
           "suggest_current" : 0
        },
```

search.open_contexts表示当前正在进行的搜索，而search.query_total表示节点启动以来完成过的总搜索数，search.query_time_in_millis表示完成上述搜索花费的时间总和。

search.fetch_total等指标含义类似。因为ES的搜索默认是query-then-fetch式的，所以fetch一般是少而快的。

1. 段合并性能

```
        "merges": {
           "current": 0,
           "current_docs": 0,
           "current_size_in_bytes": 0,
           "total": 1128,
           "total_time_in_millis": 21338523,
           "total_docs": 7241313,
           "total_size_in_bytes": 5724869463
           "total_stopped_time_in_millis" : 0,
           "total_throttled_time_in_millis" : 0,
           "total_auto_throttle_in_bytes" : 104857600
        },
```

merges数据分为两部分，current开头的是当前正在发生的短合并行为统计，total开头的是历史总计数。


1. 过滤器缓存

```
        "query_cache": {
           "memory_size_in_bytes": 48,
           "total_count" : 0,
           "hit_count" : 0,
           "miss_count" : 0,
           "cache_size" : 0,
           "cache_count" : 0,
           "evictions": 0
        },
```

query_cache.memory_size_in_bytes表示过滤器缓存使用的内存，query_cache.evictions表示因内存满被回收的缓存大小，Kibana中通过timepicker生成的filterd请求里，对`@timestamp`部分就并不是直接使用`now`，而是在浏览器上计算成毫秒数，再发送给ES的。
过滤器缓存是建立在segment基础上的

1. id缓存

```
    "id_cache": {
       "memory_size_in_bytes": 0
    },
```

id_cache是parent/child mappings使用的内存


1. fielddata
```
"fielddata": {
    "memory_size_in_bytes": 0,
       "evictions": 0
    },
```

此处显示fielddata使用的内存大小，fielddata用来做聚合，排序等工作。
**注意：fielddata.evictions应该永远是0**

1.segments:
```
        "segments": {
           "count": 1,
           "memory_in_bytes": 2042,
           "terms_memory_in_bytes" : 1510,
           "stored_fields_memory_in_bytes" : 312,
           "term_vectors_memory_in_bytes" : 0,
           "norms_memory_in_bytes" : 128,
           "points_memory_in_bytes" : 0,
           "doc_values_memory_in_bytes" : 92,
           "index_writer_memory_in_bytes" : 0,
           "version_map_memory_in_bytes" : 0,
           "fixed_bit_set_memory_in_bytes" : 0,
           "max_unsafe_auto_id_timestamp" : -1,
           "file_sizes" : {  }
        },
```

segments.count表示节点上所有索引的segment数目的总和。一个 索引通常会有50-150个segments
segments.memory_in_bytes表示segment本身底层数据结构所使用的内存大小。像索引的倒排表，词典，bloom filter等


**操作系统和进程信息**

操作系统主要包括CPU，Loadavg，Memory和Swap利用率，文件句柄等
进程，即JVM信息，主要在于GC相关数据

**GC**
Java是一个自动垃圾收集的编程语言，启动JVM虚拟机的时候，会分配固定大小的内存块，这个块叫做heap(堆)，JVM会把heap分成两个组:
+ Young新实例化的对象所分配的空间，这个空间一般来说只有100MB到500MB大小。Young空间爱你又分为两个survivor(幸存)空间，当Young空间满，就会发生一次young gc，还存活的对象就被移入幸存空间，已失效的对象则被清除

+ Old老对象存储空间，这些对象应该是长期存活并且在较长一段时间内不会变化的内容，这个空间较大。young gc空间中，如果某个对象连续多次幸存下来，就会被移进Old空间，等到Old空间满，就会发生一次old gc，把失效对象移除

在GC发生的时候，JVM需要暂停程序运行，以便自己追踪对象图收集全部失效对象。

在即诶但状态数据中，JVM相关数据:
```
"jvm": {
    "timestamp": 1408556438203,
    "uptime_in_millis": 14457,
    "mem": {
       "heap_used_in_bytes": 457252160,
       "heap_used_percent": 44,
       "heap_committed_in_bytes": 1038876672,
       "heap_max_in_bytes": 1038876672,
       "non_heap_used_in_bytes": 38680680,
       "non_heap_committed_in_bytes": 38993920,
    },
```

`heap_committed_in_bytes`指的是实际被进程使用的内存，以JVM的特性，这个值等于`heap_max_in_bytes`。`heap_max_in_bytes`则是一个更直观的阈值数据，当这个数据大于75%的时候，GC开始，


```
   "pools": {
      "young": {
         "used_in_bytes": 138467752,
         "max_in_bytes": 279183360,
         "peak_used_in_bytes": 279183360,
         "peak_max_in_bytes": 279183360
      },
      "survivor": {
         "used_in_bytes": 34865152,
         "max_in_bytes": 34865152,
         "peak_used_in_bytes": 34865152,
         "peak_max_in_bytes": 34865152
      },
      "old": {
         "used_in_bytes": 283919256,
         "max_in_bytes": 724828160,
         "peak_used_in_bytes": 283919256,
         "peak_max_in_bytes": 724828160
      }
   }
},
```
这里列出了young，survivor和Old GC区域的情况

```
    "gc": {
       "collectors": {
          "young": {
             "collection_count": 13,
             "collection_time_in_millis": 923
          },
          "old": {
             "collection_count": 0,
             "collection_time_in_millis": 0
          }
       }
    }
```
显示young和old gc的计数和耗时


**线程池信息**

一般来说，每个池子的工作线程数与CPU核数一样

ES在index，bulk，search，get，merge等各种操作都有专门的线程池

```
"index": {
   "threads": 1,
   "queue": 0,
   "active": 0,
   "rejected": 0,
   "largest": 1,
   "completed": 1
}
```

**Bulk Rejections**
发送bulk写入的时候碰到HTTP状态码429的响应报错，就会rejected。因为bulk queue里的数据是维护在内存中，所以节点发生意外死机的时候，会丢失。

如果碰到bulk rejected，可尝试以下步骤:
1. 暂停所有的写入进程
2. 从bulk响应中过滤出来rejected的那部分，因为bulk index中可能大部分成功了
3. 重发一次失败的请求
4. 恢复写入进程，或者重复上面步骤


**文件系统和网络**
```
        "transport": {
            "server_open": 13,
            "rx_count": 11696,
            "rx_size_in_bytes": 1525774,
            "tx_count": 10282,
            "tx_size_in_bytes": 1440101928
         },
         "http": {
            "current_open": 4,
            "total_opened": 23
         },
```
建议使用keep-alive长连接的客户端


**circuit Breaker**
包括request，fielddata，in_filght_requests和parent四种
```
         "in_flight_requests": {
            "maximum_size_in_bytes": 623326003,
            "maximum_size": "594.4mb",
            "estimated_size_in_bytes": 0,
            "estimated_size": "0b",
            "overhead": 1.03,
            "tripped": 0
         }
```


**ingest**
```
"ingest" : {
    "total" : {
        "count" : 0,
        "time_in_millis" : 0,
        "current" : 0,
        "failed" : 0
    },
    "pipelines" : {
        "set-something" : {
            "count" : 0,
            "time_in_millis" : 0,
            "current" : 0,
            "failed" : 0
        }
    }
}
```


**hot_threads状态**

除了stats信息以外，/_nodes/下还有另一个监控接口
```
curl -XGET 'http://127.0.0.1:9200/_nodes/_local/hot_threads?interval=60s'

```

该接口返回在`interval`时长内，该节点消耗资源最多的前三个线程的堆栈情况，默认的采用间隔是500ms，默认的，资源消耗是按照CPU来衡量的，还可以用`?type=waiting`或者`?type=block`来查看在等待和阻塞状态的当前进程排名。

