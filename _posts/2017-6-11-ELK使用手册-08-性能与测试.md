# 性能与测试

------

在Logstash5.0.0中,一大改进就是学习Elasticsearch的方式，通过API提供了一部分运行性能指标。


**生成测试数据(Generator)**

实际运行的时候这个插件是派不上用途的，但这个插件依然是非常重要的插件之一。**数据是支持操作的唯一真理**，所以上线之前，会需要在自己的实际环境中，测试Logstash和Elasticsearch的性能状况。

**配置示例**

```
input {
	generator {
		count => 1000000
		message => '{"key1":"value1","key2":[1,2],"key3":{"subkey1":"subvalue1"}}''
		codec => json	
	}
}
```

插件的默认生成数据，message内容自行定义。


**使用方法**

做测试用两种方式

+ 配合LogStash::Outputs::Null

事件流转到这里直接就略过，什么操作都不做。相当于只测试Logstash的pipe和filter效率，测试过程简单:

```
$ time ./bin/logstash -f config/generator_null.conf
real 3m0.873s
user 3m43.344s
sys  0m45.342s
```

+ 使用pv命令配置LogStash::Outputs::Stdout和LogStash::Codecs::Dots

上面这种方式虽然很好，但有小漏洞，logstash是在JVM上运行的，有一个明显的启动时间，运行也有一段事件的预热后才算稳定，所以，想要更真实的反应logstash在长期运行时候的效率，还有另一种方式：

```
output {
	stdout {
		codec => dots
	}
}
```

LogStash::Codecs::Dots也是一个另类的codec插件，它的作用是，把每个event都变成一个点(.)，这样，在输出的时候，就变成一个一个的`.`在屏幕上。显然这也是一个为了测试而存在的插件。

PV命令，这个命令就是做实时的标准输入，标准输出监控。

```
$ ./bin/logstash -f generator_dots.conf | pv -abt > /dev/null
2.2MiB 0:04:00 [24.5kiB/s]
```

jvm慢慢增长到一个稳定的状态，这时，才是需要的数值。
这里单位是B/s，但是因为一个event就输出一个`.`,也就是1B


ELK不是一个软件而是一个并不耦合的套件，所以，需要分拆开讨论这三个软件的性能如何，怎么优化?

+ LogStash的性能，是最让人迷惑的地方。因为LogStash本身并不维护队列，所以整个日志流转中任意环节的问题，都可能看起来像Logstash的问题。LogStash给自己的线程都设置了单独的线程名称，可以在`top -H`结果中具体查看线程的负载情况。

+ Elasticsearch的性能，这里需要强调的是: Elasticsearch是一个分布式系统。所以，需要关注的是: 在确定的单机处理能力的前提下，性能是否能做到线性扩展。有效利用mapping API是非常重要的

+ Kibana的性能。通常来讲，Kibana是一个单页web应用，只需要nginx发布静态文件即可，没什么性能的问题。页面加载缓慢，基本上因为Elasticsearch的请求响应时间不够快导致的。kibana本身性能可能也有关: 因为Kibana3默认是连接固定的一个ES节点的IP端口，会涉及一个浏览器的同一个IP并发连接数的限制。其次，就是Kibana用的AngulayJS使用了Promise.then的方式来处理HTTP请求响应，这是异步的。



## 心跳检测

------

缺少内部队列状态的监控办法一直是logstash令人诟病的一点，从logstash-1.5.1开始，新发布了一个logstash-input-heartbeat插件，实现了一个最基本的额队列堵塞状态监控

```
input {
	heartbeat {
		message => "epoch"
		interval => 60
		type => "heartbeat"
		add_field => {
			"zbxkey" => "logstash.heartbeat"
			"zbxhost" => "logstash_hostname"
 		}
	}
	tcp {
		port => 5160
	}
}

output {
	if [type] == "heartbeat" {
		file {
			path => "/data/logstash-log/local6-5160-%{+YYYY.MM.dd}.log"
		}
		zabbix {
			zabbix_host => "zbxhost"
			zabbix_key => "zbxkey"
			zabbix_server_host => "zabbix.example.com"
			zabbix_value => "clock"
		}
	} else {
		elasticsearch { }
	}
}
```

示例中，同时将数据输出到本地文件和zabbix server。注意，logstash-output-zabbix并不是标准插件，需要额外安装:

```
bin/logstash-plugin install logstash-output-zabbix
```

文件中记录的就是heartbeat事件的内容，示例:

```
{"clock":1435191129,"host":"logtes004.mweibo.bx.sinanode.com","@version":"1","@timestamp":"2017-06-25T00:12:09.042Z","type":"heartbeat","zbxkey":"logstash.heartbeat","zbxhost":"logstash_hostname"}
```

可以通过文件最后的clock和@timestamp内容，对比当前时间，判断logstash内部队列是否有堵塞


## JMX监控方式

------

Logstash是一个运行在JVM上的软件，也就是意味着JMX这种对JVM的通用监控方式对LogStash也是一样有效果的。要给LogStash启用JMX，需要修改`./bin/logstash.lib.sh`中`$JAVA_OPTS`变量的定义，或者在运行时设置`LS_JAVA_OPTS`环境变量

在`./bin/logstash.lib.sh`第34行`JAVA_OPTS="$JAVA_OPTS -Djava.awt.headless=true"`下，添加如下几行:

```
JAVA_OPTS="$JAVA_OPTS -Dcom.sun.management.jmxremote"
JAVA_OPTS="$JAVA_OPTS -Dcom.sun.management.jmxremote.port=9010"
JAVA_OPTS="$JAVA_OPTS -Dcom.sun.management.jmxremote.loal.only=false"
JAVA_OPTS="$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false"
JAVA_OPTS="$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false"
```

![jvm-01.png](https://aaron-13.github.io/images/jvm-01.png)

重启logstash服务，JMX配置即可生效

有JMX以后，可以通过jconsole界面查看，也可以通过zabbix等监控系统做长期监控，甚至logstash自己也有插件logstash-input-jmx来读取远程JMX数据。


**zabbix监控**

[https://www.zabbix.com/documentation/2.2/manual/config/items/itemtypes/jmx_monitoring](https://www.zabbix.com/documentation/2.2/manual/config/items/itemtypes/jmx_monitoring)

zabbix-server的java poller连接zabbix-java-gateway，由zabbix-java-gateway去获取远程JMX信息。配置zabbix-server相关进程和设置:

```
yum install zabbix-java-gateway
cat >> /etc/zabbix/zabbix-servere.conf <<EOF
JavaGateway=127.0.0.1
JavaGatewayPort=10052
StartJavaPollers=5
EOF

/etc/init.d/zabbix-java-gateway restart
/etc/init.d/zabbix-server restart
```

然后在zabbix-web上Configuration页，给运行logstash的主机的Host配置添加JMX interfaces，Port即为上面定义的9010端口

最后添加Item，Type下拉框选择`JMX agent`，Key文本框输入`jmx["java.lang:type=Memory","HeapMemoryUsage.used"]`,保存即可。

JMX有很多Key可以监控，具体的值，可以通过jconsole参看，如下图所示，如果要监控线程数，就可以写成`jmx["java.lang:type=Threading","ThreadCount"]`。



## Logstash的监控API

------

Logstash5.0开始，提供了输出自身进程的指标和状态监控的API。这大大降低了监控Logstash的难度。

目前API主要有四类:

+ 节点信息
	node info接口目前支持三种类型: pipeline,os,jvm

+ 插件信息
	用来列出已安装插件名称和版本

+ 节点指标
	node stats接口目前支持四种类型的指标

+ 热线程统计
	
**events**
获取该指标的方式为:

```
curl -s localhost:9600/_node/stats/events?pretty=true
```

LogStash和Elasticsearch一样支持使用`?pretty`参数美化JSON输出。此外，还支持`?format=yaml`来输出YAML格式的指标统计。LogStash默认监听在9600端口提供这些API访问，如果需要修改，通过`--http.port`命令行参数，或者对应的logstash.yml设置修改。


```
{
	"events" : {
		"in" : 59685,
		"filtered" : 59685,
		"out" : 59685
	}
}
```


**jvm**

获取该指标的方式:

```
curl -s localhost:9600/_node/stats/jvm?pretty=true
```

```
{
	"jvm" : {
		"threads" : {
			"count" : 32,
			"peak_count" : 34
		}
	}
}
```

**process**

获取该指标的方式:

```
curl -s localhost:9600/_node/stats/process?pretty=true
```

```
{
	"process" : {
		"peak_open_file_descriptors" : 64,
		"max_file_descriptors" : 10240,
		"open_file_descriptros" : 64,
		"mem" : {
			"total_virtual_in_bytes" : 5434534536
		},
		"cpu" : {
			"total_in_millis" : 182987232352
			"precent" : 0
		}
	}
}

```

目前beats家族有个[logstashbeat](https://github.com/consulthys/logstashbeat)项目，就是专门采用这个数据的


**pipeline**

```
curl -s localhost:9600/_node/stats/pipeline?pretty=true
```

```
{
	"pipeline": {
		"events": {
			"duration_in_millis": 782395,
			"in": 100,
			"filtered": 100
			"out": 100
		},
		"plugins": {
			"inputs": [],
            "filters": [
                {
                    "id": "grok_20e5cb7f7c9e712ef9750edf94aefb465e3e361b-2",
                    "events": {
                        "duration_in_millis": 48,
                        "in": 100,
                        "out": 100
                    },
                    "matches": 100,
                    "patterns_per_field": {
                        "message": 1
                    },
                    "name": "grok"
                },
                {
                    "id": "geoip_20e5cb7f7c9e712ef9750edf94aefb465e3e361b-3",
                    "events": {
                        "duration_in_millis": 141,
                        "in": 100,
                        "out": 100
                    },
                    "name": "geoip"
                }
            ],
            "outputs": [
                {
                    "id": "20e5cb7f7c9e712ef9750edf94aefb465e3e361b-4",
                    "events": {
                        "in": 100,
                        "out": 100
                    },
                    "name": "elasticsearch"
                }
            ]
        },
        "reloads": {
            "last_error": null,
            "successes": 0,
            "last_success_timestamp": null,
            "last_failure_timestamp": null,
            "failures": 0
        }
    }
}
```

显示了每个插件的日志处理情况(数量，耗时等)，尤其是grok过滤器插件，还显示出正则匹配失败的数量，每个字段匹配的正则表达式个数等利于排障和性能调优信息。


**热线程统计**

查看即时的线程统计情况

```
curl -s localhost:9600/_node/stats/hot_threads?human=true
```

该接口默认返回是JSON格式，在看堆栈的时候并不方便，可以用`?human=true`参数来改成文本换行的样式，效果上和Elasticsearch的/_nodes/_local/hot_threads效果一样。
节点指标API也有`?human=true`参数，其作用和`hot_threads`不一样，是把一些网络字节数，时间...改成人类更易懂的大单位。

