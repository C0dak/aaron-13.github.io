# 输出插件

------

示例

```
output {
	elasticsearch {
		hosts => ["192.168.1.1"]
		index => "logstash-%{type}-%{+YYYY.MM.dd}"
		document_type => "%{type}"
		flush_size => 20000
		idle_flush_time => 10
		sniffing => true
		template_overwrite => true
	}
}
```

**批量发送**

过去的版本中，主要由插件的`flush_size`和`idle_flush_time`两个参数共同控制LogStash向Elasticsearch发送批量数据的行为。LogStash会在20000条数据时一次性发送出去，如果10秒钟之内没有20000条，也全部发送

默认情况下，flush_size是500条，idle_flush_time是1秒。

从5.0开始，这个行为有了另一个前提: `flush_size`的大小不能超过LogStash运行时的命令行参数设置的`batch_size`,否则将以`batch_size`为批量发送的大小


**索引名**

写入的ES索引的名称，这里可以使用变量。为了更贴合日志场景，LogStash提供了`%{+YYYY.MM.dd}`这种写法。在语法解析的时候，看到以+号开头的，就会自动认为后面是时间格式，尝试用时间格式来解析后续字符串。

此外，注意索引名中不能有大写字母，否则ES在日志中会报InvalidIndexNameException，但是LogStash不会报错。


**轮询**

LogStash1.4.2在transport和http协议的情况下是固定连接指定host发送数据。从1.5.0开始，host可以设置数组，它会从节点列表中选取不同的节点发送数据。达到Round-Robin负载均衡的效果。


一个小集群里，使用node协议最方便。Logstash以Elasticsearch的client节点身份(不存数据不参加选举)运行。

![elk-01.png](https://aaron-13.github.io/images/elk-01.png)

LogStash-1.5以后，也不再分发一个内嵌的elasticsearch服务器。如果想变更node协议下的这些配置，在`$PWD/elasticsearch.yml`文件里写自定义配置即可，logstash会尝试自动加载这个文件。

对于拥有很多索引的大集群，可以使用transport协议。logstash进程会转发所有数据到指定的某台主机上。node协议下的进程是可以接收到整个elasticsearch集群状态信息的，当进程收到一个事件时，就知道这个时间应该存在集群内哪个机器的分片上，所以，会直接连接该机器发送这条数据。而transport协议下的进程不会保存这个信息。在集群状态更新(节点变化，索引变化 都会发送全量更新)时，就不会对所有的logstash进程也发送这种信息。

+ output端顺序执行，没有对日志type进行判断的各插件配置都会全部执行一次，在output段对typt进行判断的语法:

```
output {
	if [type] == "nginxaccess" {
		elasticsearch { }
	}
}

```


**模板**

Elasticsearch支持给索引预定义设置和mapping。LogStash自带一个优化好的模板:

```
{
    "template" : "logstash-*",
    "version" : 50001,
    "settings" : {
        "index.refresh_interval" : "5s"
    },
    "mappings" : {
        "_default_" : {
            "_all" : {"enabled" : true, "norms" : false},
            "dynamic_templates" : [ {
                "message_field" : {
                    "path_match" : "message",
                    "match_mapping_type" : "string",
                    "mapping" : {
                        "type" : "text",
                        "norms" : false
                    }
                }
            }, {
                "string_fields" : {
                    "match" : "*",
                    "match_mapping_type" : "string",
                    "mapping" : {
                        "type" : "text", "norms" : false,
                        "fields" : {
                            "keyword" : { "type": "keyword"  }
                        }
                    }
                }
            }  ],
            "properties" : {
                "@timestamp": { "type": "date", "include_in_all": false  },
                "@version": { "type": "keyword", "include_in_all": false  },
                "geoip"  : {
                    "dynamic": true,
                    "properties" : {
                        "ip": { "type": "ip"  },
                        "location" : { "type" : "geo_point"  },
                        "latitude" : { "type" : "half_float"  },
                        "longitude" : { "type" : "half_float"  }
                    }
                }
            }
        }
    }
}

```


+ template for index-pattern
只有匹配`logstash-*`的索引才会应用这个模板。可以把自定义的名字放在`logstash-`后面，变成`index => "logstash-custom-%{+YYYY.MM.dd}"`

+ refresh_interval for indexing
Elasticsearch是一个近实时搜索引擎。实际上是每1秒钟刷新一次数据。对于日志分析应用，可以将logstash自带的模板修改成5秒钟。还可以根据需要继续放大刷新间隔，提高数据写入性能

+ multi-field with keyword
Elasticsearch会自动使用自己的默认分词器(空格，点，斜线等分割)来分析字段。分词器对于搜索和评分非常重要，但是大大降低了索引写入和聚合请求的性能。所以logstash模板定义了一种叫"多字段"(multi-field)类型的字段。这种类型会自动添加一个".keyword"结尾的字段，并给这个字段设置为不启用分词器。简单说，你想获取url字段的聚合结果的时候，不要直接使用"url"，而是用"url.keyword"作为字段名。当你还对分词字段发起聚合和排序请求的时候，直接提示无法构建fielddata了。
在Logstash 5.0中，同时还保留携带了针对Elasticsearch 2.x的template文件，在那里，通过旧版本的mapping配置，达到和新版本相同的行为效果:对应统计字段明确设置"index":"not_analyzed","doc_values":true,以及对分此字段加上对fielddata的{"format":"disabled"}。

+ geo_point
Elasticsearch支持geo_point类型，geo distance聚合等等。比如：请求某个geo_point点方圆10千米内数据点的总数。在Kibana的tilemap类型面板中，就会用到这个类型的数据

+ half_float
Elasticsearch 5.0新引入了half_float类型，比标准的float类型占用更少的资源，提供更好地性能。


**其他模板配置建议**

+ order
如果想定制template，有以下几种选择:
1 在logstash/outputs/elasticsearch配置中开启manage_template => false选项

2 在logstash/outputs/elasticsearch配置中开启 template => "/path/to/tmpl.json"选项，让logstash发送写的template文件

3 避免变更logstash里的配置，而是另外发送一个template，利用elasticsearch的templates order功能

Elasticsearch在创建一个索引的时候，如果发现这个索引同时匹配上了多个template，那么就会先应用order数值小的template设置，然后再应用一遍order数值高的最为覆盖，最终达到一个merge的效果

```
{
	"ordre": 1,
	"template": "logstash-*",
	"settings": {
		"index.refresh_interval": "20s"
	}
}
```

然后运行 `curl -XPUT http://localhost:9200/_template/template_newid -d '@/path/to/tmpl.json'`即可
logstash默认的模板，order是0，id是logstash。


### 发送邮件

示例
```
output {
	email {
		to => "admin@website.com,root@website.com"
		cc => "other@website.com"
		via => "smtp"
		subject => "Warning: %{title}"
		options => {
			smtpIporHost => "localhost",
			port => "25",
			domain => 'localhost.localdomain',
			userName => aaron,
			password => pass,
			authenticationType => aaron, # (plain,login and cram_md5)
			starttls => true
		}
		htmlbody => ""
		body => ""
		attachments => ['/path/to/filename']
	}
}
```

以上示例适用于logstash1.5，options =>的参数配置在Logstash2.0之后的版本已被移除

```
output {
	email {
		port => "25"
		address => "smtp.126.com"
		username => "test@126.com"
		password => "pass"
		authentication => "plain"
		use_tls => true
		from => "test@126.com"
		subject => "Warninng: %{title}"
		to => "test@qq.com"
		via => "smtp"
		body => "%{message}"
	}
}
```

outputs/email插件支持SMTP协议和sendmail两种方式，通过via参数设置



### 调用命令执行(Exec)
outputs/exec插件的运用如下，将logstash切割成的内容作为参数传递给命令。这样，在每个事件到达该插件的时候，都会触发这个命令的执行。

```
output {
	exec {
		command => "sendsms.pl \"%{message}\" -t %{user}"
	}
}

```

这种方式是每次都重新开始执行一次命令并退出。本身是比较慢速的处理方式(程序加载，网络建联等都有一定的时间消耗)。最好只用于少量的信息处理场景，比如不适用nagios的其他报警方式。



### 保存成文件(File)
通过日志收集系统将分散在数百台服务器上的数据集中存储在某中心服务器上。和Logstash::Inputs::File不同，Logstash::Outputs::File里可以使用sprintf format格式来自动定义输出带日期命名的路径

```
output {
	file {
		path => "/path/to/%{+YYYY.MM.dd}/%{host}.log.gz"
		message_format => "%{message}"
		gzip => true
	}
}

```

插件默认是输出这个event的JSON形式数据的。这可能与大多数情况下使用者的期望不符，可能只希望以原始格式保存。所以要定义为`%{message}`，前提在之前的filter插件中，没有使用remove_field或者update等参数删除或修改`%{message}`字段内容

gzip格式是一个非常奇特而友好的格式，其格式包括有:

+ 10字节的头，包含幻数，版本号以及时间戳

+ 可选的扩展头，如原文件名

+ 文件体，包括DEFAULT压缩的数据

+ 8字节的尾注，包括CRC-32校验和以及未压缩的原始数据长度


**注意**

1 按照Logstash标准，其实应该可以把数据格式的定义改在codec插件中完成，但是logstash-output-file插件内部实现中跳过了@codec.decode这步，所以`codec设置无法生效`

2 按照Logstash标准，配置参数的值可以使用event sprintf格式，但是logstash-output-file插件对event.sprintf(@path)的结果，还附加了一步`inside_file_root?`校验，这个file_root是通过直接对path参数分割/ 符号得到的，如果在sprintf格式中带有/符号，那么被切分后的结果就无法正确解析



### zabbix

bin/logstash-plugin install logstash-output-zabbix

信息以键值对的方式输出到zabbix服务器。事件的时间戳会自动关联zabbix项目

![zabbix-01.png](https://aaron-13.github.io/images/zabbix-01.png)

每个`host`是个标识，每个项目都关联到对应的主机。
现在该插件还不能批量发送数据。

该插件会记录一个警告如果一个必要的字段丢失，不会尝试重发，如果zabbix服务停止，但是会记录一个错误信息

![zabbix-02.png](https://aaron-13.github.io/images/zabbix-02.png)

+ codec 
codec类型的默认值是`plain`

+ multi_value
值是一个数组，没有默认值
使用`multi_value`直接发送多组键值对

```
[zabbix_key1,zabbix_value1,zabbix_key2,zabbix_value2,...zabbix_keyN,zabbix_valueN]
```

+ timeout
值的类型是number，默认是1秒
放弃一个与zabbix server连接之前的等待时间

+ workers
值的类型是number，默认值是1
输出的线程数，此设置并不会对所有的输出有效

+ zabbix_host
这是一个必要的设置，值的类型是字符串，没有默认值

+ zabbix_key
值的类型是字符串，没有默认值
如果使用了multi_value，此设置会被直接忽略

+ zabbix_server_host
值的类型是字符串
默认值是localhost

+ zabbix_server_port
值的类型是数值，默认值是10051

+ zabbix_value
值的类型是字符串，默认值是"message"
此字段名是用来存储你想发送的信息，会被直接忽略如果使用了multi_value



### 输出到Statsd

Statsd是用Perl写的针对Graphite，datadog等监控数据就断存储开发的前端网络应用。用户接收(默认UDP)，写入，读取和聚合时间序列数据，包括即时值和累积值等。
Graphite使用Python模仿RRDtools写的时间序列数据库套件，包括三部分:

+ carbon: 是一个Twisted守护进程，监听处理数据

+ whisper: 存储时间序列的数据库

+ webapp: 一个用Django框架实现的网页应用


**Graphite安装简介**

1 安装cairo和pycairo库

```
yum -y install cairo pycairo
```

2 pip安装

```
yum install python-devel python-pip
pip install django django-tagging carbon whisper graphite-web uwsgi
```

3 配置Graphite

```
cd /opt/graphite/webapp/graphite
cp local_setting.py.example local_settings.py
python manage.py syncdb
```

修改local_setting.py中的DATABASE为设置的db信息

4 启动cabon

```
cd /opt/graphite/conf/
cp carbon.conf.example carbon.conf
cp storage-schemas.conf.example storage-schemas.conf
cd /opt/grahite/
./bin/carbon-cache.py start
```


**statsd安装简介**

1 Graphite地址配置

```
cd /opt/
git clone git://github.com/etsy/statsd.git
cd /opt/statsd
cp exampleConfig.js Config.js

```

根据Graphite服务器地址，修改Config.js中的配置如下:

```
{
	graphitePort: 2003,
	graphiteHost: "10.10.10.10",
	port: 8125,
	backend: ["./backends/graphite"]
}
```

uwsgi配置

```
cd /opt/graphite/webapp/graphite
cat > wsgi_graphite.xml << EOF
<uwsgi>
	<socket>0.0.0.0:8630</socket>
	<workers>2</workers>
	<processes>2</processes>
	<listen>100</listen>
	<chdir>/pot/graphite/webapp/graphite</chdir>
	<pythonpath>..</pythonpath>
	<module>wsgi</module>
	<pidfile>graphite.pid</pidfile>
	<master>true</master>
	<enable-threads>true</enable-threads>
	<logdate>true</logdate>
	<daemonize>/var/log/uwsgi_graphite.log</daemonize>
</uwsgi>
EOF
cp /opt/graphite/conf/graphite.wsgi /opt/graphite/webapp/graphite/wsgi.py

```

1 nginx的uwsgi配置

```
cat > /etc/nginx/conf.d/graphite.conf << EOF
server {
	listen 8081;
	server_name graphite;

	access_log /opt/graphite/storage/log/webapp/access.log
	error_log /opt/graphite/storage/log/webapp/error.log

	location / {
		uwsgi_pass 0.0.0.0:8630;
		include uwsgii_params;
		proxy_connect_timeout 300;
		proxy_send_timeout 300;
		proxy_write_timeout 300;
	}
}
EOF
```

启动

```
uwsgi -x /opt/graphite/webapp/graphite/wsgi_graphite.xml
systemctl nginx reload

```

数据测试

```
echo "test.logstash.num:100 | c " | nc -w 1 -u $IP $port
```

如果配置正常，在graphite左侧metrics->stats->test->logstash->num表，statsd里面多了numStats等数据

配置示例

```
output {
	statsd {
		host => "statsdserver.domain.com"
		namespace => "logstash"
		sender => "%{host}"
		increment => ["httpd.response.%{status}"]
	}
}
```

Graphite以树状结构存储监控数据，所以statsd也是如此。发送给statsd的数据的key也一定是"first.second.three.four"这样的形式，而在logstash-output-statsd插件中，就会以三个配置参数来拼接成这种形式:

```
namespace.sender.metric
```

其中namespace和sender都是直接设置的，而metric又分为好几个不同的参数可以分别设置，statsd支持的metric类型如下:

**metric类型**

+ increment增量，一个计量周期内，某个数字被接收了多少次，比如nginx的status状态码
`increment => ["nginx.status.%{status}"]`

+ decrement
语法同increment

+ count对数字的计数，比如nginx的body_bytes_sent
`count => {"nginx.bytes" => "%{bytes}"}`

+ gauge
语法同count

+ set
语法同count

+ timing时间范围内，某种数字的最大值，最小值，平均值，比如nginx的响应时间request_time
语法同count

关于metric类型的详细说明[https://github.com/etsy/statd/blob/master/docs/metric_types.md](https://github.com/etsy/statd/blob/master/docs/metric_types.md)



### 标准输出(stdout)

```
output {
	stdout {
		codec => rubydebug
		worker => 2
	}
}

```

输出插件统一具有一个参数workers，logstash为输出做了多线程的准备
完全写法:
`codec => rubydebug {}`



### 发送网络数据(TCP)

```
output {
	tcp {
		hostt => "192.168.1.1"
		port => 8888
		codec => json_lines
	}
}
```

在收集端采用tcp方法发送给远端tcp端口，默认的codec选项是json。而远端的LogStash::Inputs::TCP的默认codec选项是line。所以不指定各自的codec，对接会失败。
另外，由于IO BUFFER的原因，即使是两端共同约定json依然无法正常运行，接收端会认为一行数据没结束，一直等待直到outofmemory
所以正确的做法，发送端指定codec为json_lines，这样每条数据后面加上一个回车



### HDFS

```
output {
	hadoop_webhdfs {
		workers => 2
		server => "nameno.de:14000"
		user => "aaron"
		path => "/user/flume/logstash/dt=%{+Y}-%{+M}-%{+d}/logstash/-%{+H}.log"
		flush_size => 500
		compress => "snappy"
		idle_flush_time => 10
		retry_interval => 0.5
	}
}
```

**Configuration**

```
output {
	hdfs {
		path => "/path/to/output_file.log"
		enable_append => true
	}
}
```

**How To Run**

```
CLASSPATH=$(find /path/to/hadoop -name '*.jar' | tr '\n' ':'):/etc/hadoop/conf:/path/to/logstash-1.1.7-monolithic.jar java logstash.runner agent -f conf/hdfs-output.conf -p /path/to/cloned/logstash-hdfs
```



