# 增产改查

------

增删改查是数据库的基础操作方法

**数据写入**
ES一大特点，就是全RESTful接口处理JSON请求

```
curl -XPOST http://127.0.0.1:9200/logstash-2017-06-12/testlog -d '{
    "date": "1434966686000",
    "user": "aaron",
    "mesg": "test"
}'
```

**数据写入**

```
curl -XGET http://127.0.0.1:9200/logstash-2017-06-12/testlog/_id值
```


**数据删除**

```
curl -XDELETE http://127.0.0.1:9200/logstash-2017-06-12/testlog/_id值

curl -XDELTE http://127.0.0.1:9200/logstash-2017-06-*
删除整个索引

```

**数据更新**

有两种方式，一种是全量提交，即指明`_id`再发送一些写入请求

```
curl -XPOST http://127.0.0.1:9200/logstash-2017-06-12/testlog/_id值 -d '{
    ...
}'
```

另一种是局部更新，使用/_update接口:

```
curl -XPOST http://127.0.0.1:9200/logstash-2017-06-12/testlog/_id值/_update -d '{
    ...
}'
```


## 搜索请求

ES5.0之前，刚写入的数据，可以通过translog立即获得，但要等到refresh称为一个segment，才能被搜索到。5.0之后，一旦GET不到，就强制refresh出来segment，降低了数据获取性能，但节省了内存，减少young GC次数。

**全文搜索**

```
curl -XGET http://127.0.0.1:9200/logstash-2017-06-12/testlog/_search?q=first
```

其结果为:
```
{"took":240,"timed_out":false,"_shards":{"total":27,"successful":27,"failed":0},"hits":{"total":1,"max_score":0.11506981,"hits":[{"_index":"logstash-2017-06-12","_type":"testlog","_id":"AU4ew3h2nBE6n0qcyVJK","_score":0.11506981,"_source":{
    "date" : "1434966686000",
    "user" : "aaron",
    "mesg" : "first message into Elasticsearch"
}}]}}

```

等同于:
```
curl -XGET http://127.0.0.1:9200/logstash-2017-06-12/testlog/_search?q=user:"aaron"
```

**querystring语法**

`?q=`后面写的，是querystring语法

+ 全文检索:直接写搜索单词，如上例中的`first`

+ 带字段的全文检索: 在搜索单词之前加上字段名和冒号，比如 `mesg:first`

+ 单字段的精确搜索: 在搜索单词前后加上双引号，`user:"aaron"`

+ 多个检索条件的组合: 可以使用`NOT`,`AND`,`OR`来组合检索，`user:("aaron" OR "aaron-13") AND NOT mesg:first`

+ 字段是否存在: `_exists_:user`表示要求user字段存在，`_missing_:user`表示要求user字段不存在

+ 通配符: 用`?`表示单字母，用`*`表示任意字母，`fir?t mess*`

+ 正则: `mesg:/mesg{2}ages?/`,ES中正则性能较差，尽量不使用，[语法](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-regexp-query.html#regexp-syntax)

+ 近似搜索: 用`~`表示搜索单词坑内有一两个字母写的不对，请ES按照相似度返回结果，比如:`first~`

+ 搜索范围: 对数值和时间爱你，ES都可以使用范围搜索，比如: `rtt:>300`,`date:["now-6h" TO "now"}`,其中，`[]`表示端点数值包含在范围内，`{}`表示端点数值不包含在范围内


**完整语法**

ES支持各种类型的检索请求，具体参见[https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-queries.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-queries.html)

term query的写法，相当于querystring语法中`user:"aaron"`

```
curl -XGET http://127.0.0.1:9200/_search -d '{
    "query": {
        "term": {
            "user": "aaron"
        }
    }
}'
```

**聚合请求**
在检索范围确定后，ES还支持对结果集做聚合查询，返回更直接的聚合统计结果，ES1.0之前，接口叫做Facet，1.0之后改为Aggregation


**堆叠聚合示例**

在Elasticsearch1.x中，aggregation分为bucket和metric两种，分别用作词元划分和数值计算，bucket aggregation还支持在自身结果集上，叠加新的aggregation，比如一个时序百分比统计:

```
curl -XPOST 'http://127.0.0.1:9200/logstash-2017-06-12/_search?size=0&pretty' -d '{
    "aggs": {
        "percentile_over_time": {
            "date_histogram": {
                "field" : "@timestamp",
                "interval": "1h"
            },
            "aggs": {
                "percentile_one_time": {
                    "percentiles": {
                        "field": "requesttime"
                    }
                }
            }
        }
    }
}'
```

结果如下
```
{
  "took" : 151595,
  "timed_out" : false,
  "_shards" : {
    "total" : 81,
    "successful" : 81,
    "failed" : 0
  },
  "hits" : {
    "total" : 3307142043,
    "max_score" : 1.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "percentile_over_time" : {
      "buckets" : [ {
        "key_as_string" : "12/Jun/2017:22:00:00 +0000",
        "key" : 1435010400000,
        "doc_count" : 459273981,
        "percentile_one_time" : {
          "values" : {
            "1.0" : 0.004,
            "5.0" : 0.006,
            "25.0" : 0.023,
            "50.0" : 0.035,
            "75.0" : 0.08774675719725569,
            "95.0" : 0.25732934416125663,
            "99.0" : 0.7508899754871812
          }
        }
      }, {
        "key_as_string" : "12/Jun/2017:00:00:00 +0000",
        "key" : 1435017600000,
        "doc_count" : 768620219,
        "percentile_one_time" : {
          "values" : {
            "1.0" : 0.004,
            "5.0" : 0.007000000000000001,
            "25.0" : 0.025,
            "50.0" : 0.03987809503972864,
            "75.0" : 0.10297843567746187,
            "95.0" : 0.30047269327062875,
            "99.0" : 1.015495933753329
          }
        }
      }, {
        "key_as_string" : "12/Jun/2017:02:00:00 +0000",
        "key" : 1435024800000,
        "doc_count" : 849467060,
        "percentile_one_time" : {
          "values" : {
            "1.0" : 0.004,
            "5.0" : 0.008,
            "25.0" : 0.027000000000000003,
            "50.0" : 0.0439999899006102,
            "75.0" : 0.1160416197625958,
            "95.0" : 0.3383140614483838,
            "99.0" : 1.0275839684542212
          }
        }
      } ]
    }
  }
}
```


**管道聚合示例**

在ES2.x中，新增了pipeline aggregation类型，在已有返回的数组数据之后，再对这组数据做一次运算，最常见的，就是对时序数据求移动平均值。


**buckets_path语法**

aggregation是有堆叠层级关系，pipeline aggregation在引用metric aggregation时会涉及到层级的问题
参见[https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html)


**search请求参数**

+ from: 从索引的第几条数据开始返回，默认是0

+ size: 返回多少条数据，默认是10
注意: Elasticsearch集群是需要给coordinate node返回`shards number * (from + size)`条数据，然后在单机上进行排序，最后给客户端返回这个size大小的数据的
Elasticsearch2.x新增了一个索引级别的动态控制配置项:`index.max_result_window`默认为10000，如果from+size大于这个值，则拒绝掉这次请求

+ timed_out: coordinate node等待超时时间，到达该阈值后，coordinate node直接把当前收到的数据返回给客户端，不再继续等待data node后续的返回

+ terminate_after: 各data node上，扫描单个分片时，找到多少条数据，就认为够了

+ request_cache: 各data node上，在分片级别，对请求的响应(仅限于hits.total数值，aggregation和suggestion的结果集)做的缓存，这个缓存的键值要求严格，一字不差，才能命中

`request_cache`参数不能写在请求JSON里，只能以URL参数的形式存在。
```
curl  -XPOST http://127.0.0.1:9200/_search?request_cache=true -d '{
    "size": 0,
    "timeout": "120s",
    "terminate_after": 1000000,
    "query": {"match_all": {}},
    "aggs": {"terms": {"terms":{"field":"keyname"}}}
}'
```







