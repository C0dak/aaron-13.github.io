# Perf简介

------

Perf是用来进行软件性能分析的工具。

通过它，应用程序可以利用PMU，tracepoint和内核中的特殊计数器来进行性能统计，不但可以分析指定应用程序的性能问题(per thread)，也可以用来分析内核的性能问题，也可以同时分析应用代码和内核，从而全面理解应用程序中的性能瓶颈。

最初叫做Performance counter，在2.6.31中第一次亮相。在2.6.32中，它正式改名为Performance Event，因为perf已不再仅仅作为PMU的抽象，而是能够处理所有的性能相关的事件。

使用perf，可以分析程序运行期间发生的硬件事件，比如instructions retried(指令重试)，processor clock cycles(处理器时钟周期)等，也可以分析软件事件，如PageFault和进程切换。

这使得Perf拥有了众多的性能分析能力，举例来说，使用Perf可以计算每个时钟周期内的指令数，成为IPC，IPC偏低表明CPU利用率低。Perf还可以对程序进行函数级别的采样，从而了解程序的性能瓶颈究竟在哪里。Perf还可以代替strace，可以动态添加内核probe点，还可以做benchmark衡量调度器的好坏...



**背景知识**

有些背景知识是分析性能问题时需要了解的，比如硬件cache；再比如操作系统内核。应用程序的行为细节往往是和这些相互牵扯的，这些底层的东西会以意想不到的方式影响应用程序的性能，比如某些程序无法充分利用cache，从而导致性能下降。比如调用过多的不必要的系统调用，造成频繁的内核/用户切换等。

**性能相关的处理器硬件特性，PMU简介**
当算法已经优化，代码不断精简，调到最后，便需要斤斤计较，cache，流水线一类平时不大注意的东西也必须精打细算了

**硬件特性之cache**
内存读写是很快的，但还是无法和处理器的指令执行速度相比，为了从内存中读取指令和数据，处理器需要等待，用处理器时间来衡量，这等待是漫长的。Cache是一种SRAM(静态随机存取存储器，一种具有静止存取功能的内存，不需要刷新电路即能保存它内部存储的数据)，它的读写速率非常快，能和处理器处理速度相匹配，因此将常用的数据保存在cache中，处理器便无需等待，从而提高性能。Cache的尺寸一般都很小，充分利用cache是软件调优非常重要的部分。

**硬件特性之流水线，超标量体系结构，乱序执行**
提高性能最有效的方式之一就是并行，处理器在硬件设计时也尽可能地并行，比如流水线，
超标量体系结构以及乱序执行。
处理器处理一条指令需要分多个步骤完成，比如先去指令，然后完成运算，最后将计算结果输出到总线上。在处理器内部，这可以看做一个三级流水线
![perf-01.png](https://aaron-13.github.io/images/perf-01.png)

指令从左边进入处理器，上图中的流水线有三级，一个时钟周期可以同时处理三条指令，分别被流水线的不同部分处理。

超标量(superscalar)指一个时钟周期发射多条指令的流水线机器架构，比如Inter的Pentium处理器，内部有两个执行单元，在一个时钟周期内语序执行两条指令。
此外，在处理器内部，不同指令所需要的处理步骤和时钟周期是不同的，如果严格按照程序的执行顺序执行，那么就无法充分利用处理器的流水线。因此执行可能会被乱序执行。

上述三种并行技术对所执行的指令有一个基本要求，即相邻的指令相互没有依赖关系。加入某条指令需要依赖前面一条指令的执行结果数据，那么pipeline便失去作用，因为第二条指令必须等待第一条指令完成。因此好的软件应该尽量避免这种代码的生成。

**硬件特性之分支预测**
分支指令对软件性能有比较大的影响。尤其是当处理器采用流水线设计之后，假设流水线有三级，当前进入流水的第一个指令为分之指令。假如处理器顺序读取指令，那么如果分支的结果是跳转到其他指令，那么被处理器流水线预测的后续两条指令都将被抛弃，从而影响性能。为此，很多处理器都提供了分支预测功能，根据同一条指令的历史执行记录进行预测读取最可能的下一条指令，而并非顺序读取指令。

分支预测对软件结构有一些要求，对于重复性的分支指令序列，分支预测硬件能得到较好的预测结果，而对于类似switch case一类的程序结构，则往往无法得到理想的预测结果。

上面介绍的几种处理器特性对软件的性能有很大的影响，然而依赖时钟定期采样的profiler模式无法揭示程序对这些处理器硬件特性的使用情况。处理器厂商针对这种情况，在硬件中加入PMU单元，即Performance monitor unit。

PMU允许软件针对某种硬件事件设置counter，此后处理器便开始统计该事件的发生次数，当发生的次数超过counter内设置的值后，便产生中断，比如cache miss达到某个值后，PMU便能产生相应的中断。

捕获这些中断，便可以考察程序对这些硬件特性的利用效率。


**Tracepoints**
Tracepoint是散落在内核源码中的一些hook，一旦使用，它们便可以在特定的代码被运行到时被触发，这一特性可以被各种trace/debug工具所使用，Perf就是考察程序对这些硬件特性的利用效率了。

假如想知道在应用程序运行期间，内核内存管理模块的行为，便可以利用潜伏在slab分配器中的tracepoint。当内核运行到这些tracepoint时，便会通知perf。

Perf将tracepoint产生的事件记录下来，生成报告，通过分析这些报告，调优人员可以了解程序运行时期内核的种种细节，对性能症状做出准确的诊断。


------

**perf的基本使用**

函数longa()是个很长的循环，比较浪费时间，函数foo1和foo2将分别调用该函数10次，以及100次

```c
#include<stdio.h>
#include<stdlib.h>

 void longa() 
 { 
   int i,j; 
   for(i = 0; i < 1000000; i++) 
   j=i; //am I silly or crazy? I feel boring and desperate. 
 } 

 void foo2() 
 { 
   int i; 
   for(i=0 ; i < 10; i++) 
        longa(); 
 } 

 void foo1() 
 { 
   int i; 
   for(i = 0; i< 100; i++) 
      longa(); 
 } 

 int main(void) 
 { 
   foo1(); 
   foo2(); 
 }

 ```

 **准备使用perf**

 安装perf，要求2.6.31以上的内核版本，进入tools/perf目录执行
 ```
 make
 make install
 ```

 性能调优工具如perf，Oprofile等的基本原理都是对被监测的对象进行采样，最简单的形式是根据tick中断进行采样，即在tick中断内触发采样点，在采样点里判断程序当时的上下文。假如一个程序的90%时间都花费在函数foo()上，那么90%的采样点都应该落在函数foo()的上下文中。通过tick触发采样，可以了解程序中哪些地方最耗时间，从而重点分析。
 通过改变采样的触发条件可以获得不同的统计数据。
 以时间点(如tick)作为事件触发采样便可以获知程序运行时间的分布。
 以cache miss事件触发采样便可以知道cache miss的分布，即cache失效经常发生在哪些程序代码中。

 perf中能够触发采样的事件有：

 **Perf list, perf事件**

 使用perf list命令可以列出所有能够触发perf采样点的事件

![perf-03.png](https://aaron-13.github.io/images/perf-03.png)

不同系统会列出不同的结果，在2.6.35版本中的内核中，该列表已经相当长，但无论多少，我们可以将它们分为三类：

Hardware Event是有PMU硬件产生的事件，比如cache命中，当需要了解程序对硬件特性的使用情况时，便需要对这些事件进行采样；
Software Event是内湖软件产生的事件，比如进程切换，tick数等
Tracepoint event是内核中的静态tracepoint所触发的事件，这些tracepoint用来判断程序运行期间内核的行为细节，比如slab分配器的分配次数等。
上述每一个事件都可以用于采样，并生成一项统计数据，时至今日，尚没有文档对每个event的含义进行详细解释。


**Perf start**
面对一个问题程序，最好采用自顶向下的策略。先整体看看该程序运行时各种统计事件的大概，再针对某些方向深入细节。而不是一下子扎进琐碎细节，会一叶障目。
有些程序慢是因为计算量太大，其多数时间都应该在使用CPU进行计算，这叫做CPU bound型，有些程序慢是因为过多的IO，这种时候其CPU利用率应该不高，这叫做IO bound型；对于CPU bound程序的调优和IO bound的调优是不同的。
perf stat通过概括精简的方式提供被调试程序运行的整体情况和汇总数据。

`gcc -o t1 test.c`

![perf-05.png](https://aaron-13.github.io/images/perf-05.png)

对t1进行调优应该要找到热点(即最耗时的代码片段)，再看看是否能够提高热点代码的效率。


缺省情况下，除了task-clock-msecs之外，perf stat还给出了其他几个最常用的统计信息：
Task-clock-msecs：CPU利用率，该值高，说明程序的多数时间花费在CPU计算上而非IO
Context-switches：进程切换次数，记录了程序运行过程中发生了多少次进程切换，频繁的进程切换是应该避免的。
Cache-misses：程序运行过程中总体的cache利用率，如果该值过高，说明程序的cache利用不好。
CPU-migrations: 表明进程t1运行过程中发生了多少次CPU迁移，即被调度器从一个CPU转移到另一个CPU上运行。
Cycles：处理器时钟，一条机器指令可能需要多个cycles。
Instructions:  机器指令数目
IPC：是Instructions/Cycles的比值，该值越大越好，说明程序充分利用了处理器特性
Cache-references: cache命中的次数
Cache-misses: cache失效的次数。

通过指定-e选项，可以改变perf stat的缺省事件。


**Perf top**

使用perf stat的时候，万网已经有一个调优的目标。也有些时候，系统性能无端下降，并不清楚哪个进程成为了贪吃的hog。
此时需要一个类似top的命令，流出所有值得怀疑的进程，从中找到需要进一步审查的家伙。
Perf top用于实时显示当前系统的性能统计信息，该命令主要用来观察整个系统当前的状态，，如果可以设置查看该命令的输出来查看但前系统耗时的内部函数或某个用户进程。

```
while (1) i++;
```

![perf-06.png](https://aaron-13.github.io/images/perf-06.png)


**使用perf record解读report**

要进一步分析，便需要一些粒度更细的信息，就需要使用Perfrecord记录单个函数级别的同级信息，并使用perf report来显示统计结果。
调优应该将注意力集中到百分比高的热点代码片段上。

```
perf record -e cpu-clock ./t1
perf report
```

perf -g report
![perf-07.png](https://aaron-13.github.io/images/perf-07.png)

通过对calling graph的分析，能方便地看到91%的时间都花费在foo1()函数中，因为调用100次longa()函数，因此假如longa()是个无法优化的函数，那么程序员应该考虑优化foo1，减少对longa()的调用次数。


**使用PMU的例子**

下面例子参考文章[Branch and Loop Reorganization to Prevent Mispredicts](https://software.intel.com/en-us/articles/branch-and-loop-reorganization-to-prevent-mispredicts/?cm_mc_uid=74481043479314979481495&cm_mc_sid_50200000=1499999829)

该例子考察程序对奔腾处理器分之预测的利用率，如前所述，分支预测能够显著提高处理器的性能，而分支预测失败则显著降低处理器的性能，首先给出一个存在BTB失效的例子

![perf-08.png](https://aaron-13.github.io/images/perf-08.png)

使用perf stat考察分支预测的使用情况

![perf-09.png](https://aaron-13.github.io/images/perf-09.png)

可以看到branche-misses的情况严重，25%左右，处理器为Pentium4，其BTB大小为16，而test.c中的循环迭代为20次，BTB溢出，所以处理器的分支预测将不准确。

循环的汇编
```
// C code
for (i=0;i<20;i++)
{...}

//Assembly code
mov    esi,data
mov    ecx,0
ForLoop:
cmp    ecx,20
jge
EndForLoop
...
add    ecx,1
jmp    ForLoop
EndForLoop:
```

可以看到，每次循环迭代中都有一个分支语句jge，因此在运行过程中将有20次分支判断。每次分支判断都将写入BTB，但BTB是一个ring buffer，16个slot(位槽)写满后便开始覆盖。超过16次，则BTB应该如下图显示：

![perf-10.png](https://aaron-10.png/images/perf-10.png)

这个buffer完全精确地描述了整个循环迭代的分支判定情况，因此下次运行同一个循环时，处理器便可以做出正确的预测，假如迭代次数为20，则该BTB随着时间推移而不能完全准确的描述该循环的分支预测执行情况，处理器将做出错误的判断。

将循环迭代的次数减少为10次，其结果为：

![pref-11.png](https://aaron-13.github.io/images/perf-11.png)


branch-miss减少了。


**使用tracepoint**

当perf根据tick时间点进行采样，便能够得到内核代码中的hot spot，
使用tracepoint的基本需求是对内核的运行时行为的关心。如需要关注特定的子系统，内存管理模块等，便需要统计相关内核函数的运行情况，另外，内核行为对应用程序性能的影响也是不容忽视的。

raw_syscalls:sys_enter --> syscalls:sys_enter
具体的event可通过perf list进行查看

![perf-13.png](https://aaron-13.github.io/images/perf-13.png)

这个报告详细说明了在ls运行期间发生了多少次系统调用，多数调用发生在哪些地方。


**Perf probe**

tracepoint是静态检查点，意思是一旦它在哪里，便一直在那里。
Perf并不是第一个提供这个功能的软件，systemTap早就实现了。

![perf-14.png](https://aaron-13.github.io/images/perf-14.png)

利用probe命令在内核函数schedule()的第12行加入一个动态probe点，和tracepoint的功能一样，内核一旦运行到该probe点时，便会通知perf。可以理解为动态增加了一个新的tracepoint。


**Perf sched**

调度器的好坏直接影响一个系统的整体运行效率。

Perf sched有五个自命令
```
perf sched record  		#任意工作负载的低开销记录
perf sched latency 		#每个任务潜在延迟值的输出
perf sched map 			#显示上下文切换的摘要/映射
perf sched trace		#显示详细的追踪
perf sched reply		#重放使用模拟线程捕获的工作负载

用户一般使用`perf sched record`收集调度相关的数据，然后就可以用`perf sched latency`

![perf-15.png](https://aaron-13.github.io/images/perf-15.png)

最值得关注的是Maximum delay，一般从这里可以看到对交互性影响最大的特性：调度延迟，如果调度延迟比较大，那么就会影响用户体验。

其他的三个子命令提供了不同的视图。

![perf-16.png](https://aaron-13.github.io/images/perf-16.png)

星号表示调度事件发生所在的CPU。
点好表示该CPU正在IDLE。

Map的好处在于提供了一个总的视图，将成百上千的调度事件进行总结，显示了系统任务在CPU之间的分布，假如有不好的调度迁移，比如一个任务没有被及时迁移到idle的CPU却被迁移到忙碌的CPU，类似这种调度器的问题可以从map的报告中一眼看出来。


map提供了高度概括的总体报告，那么trace提供了最详细，最底层的细节报告。

![perf-17.png](https://aaron-13.github.io/images/perf-17.png)


perf replay这个工具是为调度器开发人员设计的，它试图重放perf.data文件中所记录的调度场景，使用Perf replay，perf将模拟perf.data中的场景，无需花时间去重现，利于调试过程。

![perf-18.png](https://aaron-13.github.io/images/perf-18.png)


**perf bench**

除了调度器之外，很多时候需要衡量自己的工作对系统性能的影响。benchmark是衡量性能的标准方法。

Perf bench目前提供了三个benchmark：

1. Sched message

![perf-20.png](https://aaron-13.github.io/images/perf-20.png)

sched message是从经典的测试程序hackbench移植而来，用来衡量调度器的性能，overhead以及扩展性，该benchmark启动N个reader/sender进程或线程对，通过IPC(socket或者pipe)进行并发的读写，一般人们将N不断增大来衡量调度器的可扩展性。


2. sched pipe

![perf-21.png](https://aaron-13.github.io/images/perf-21.png)

sched pipe从Ingo Molnar的pipe-test-1m.c移植而来，当初Ingo的原始程序为了测试不同的调度器性能和公平性，其工作原理就是两个进程相互通过pipe拼命地发1000000个整数，进程A发给B，同时B发给A，因为AB相互依赖，因此假如调度器不公平，对A比B号，那么A和B整体所需要的时间就会比较长。


3. Mem memcpy
衡量一个拷贝1M数据的memcpy()函数所花费的时间。


**Perf lock**

锁是内核同步的方法，一旦加了锁，其他准备加锁的内核执行路径就必须等待，降低了并行，。因此对锁进行专门分析应该是调优的一项重要工作。

![perf-22.png](https://aaron-13.github.io/images/perf-22.png)

"Name": 锁的名字，比如md->map_lock，即定义在dm.c中结构mapped_device中的读写锁

"acquired": 该锁被直接获得的次数，即没有其他内核路径拥有该锁的情况下得到该锁的次数。

"contented": 冲突的次数，即在准备获得该锁的时候已经被其他人所拥有的情况的出现次数

"total wait": 为了获得该锁，总共的等待时间

"max wait": 为了获得该锁，最大的等待时间

"min wait": 为了获得该锁，最小的等待时间


**perf Kmem**
Perf Kmem专门收集内核slab分配器的相关事件，比如内存分配，释放等。可以用来研究程序在哪里分配了大量内存，或者在什么地方产生碎片之类的和内存管理相关的问题。

![perf-23.png](https://aaron-13.github.io/images/pref-23.png)










