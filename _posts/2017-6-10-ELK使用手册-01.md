# ELK使用手册-01
------

## Logstash
Logstash是一种分布式日志收集框架，使用JRuby语言开发，与Elasticsearch，Kibana配置，组成ELK技术栈，非常适合用来做日志数据的分析
当然，也可以单独出现，作为日志收集软件，可以将日志收集到多种存储系统或临时中转系统，如MySQL，Redis，kafka，HDFS，lucene等。

**命令格式**
/bin/logstash 命令参数 选项

**选项**
	-f: 指定加载一个后缀为.conf文件的logstash配置文件
	-e: 命令行指定参数，通常用来调试
	-w: 指定logstash的工作线程数
	-l: 指定logstash的默认日志写入到一个文件中，如果不指定，默认是标准输出
	--quiet: 静默模式，仅输出error级别的信息
	--verbose: info级别的log日志
	--debug: debug级别的log日志
	-V,--version: 版本查看
	-p,--pluginpath PATH: 加载自定义的logstash插件
	-t,--configtest: 检查logstash配置文件是否有效
	-h,--help: 帮助信息

**logstash的数据处理模型**
`input=>output
input=>filter=>output`
其中input常用的输入源有: file,syslog,redis,log4j,apache log或nginx log，或者其他一些自定义的log格式，业务log，搜索log，订单log等等

**filter常用的选项**
	grok: 支持正则提取任何非结构化数据或结构化数据，其中logstatsh内置120多种正则，比如常见的时间，ip，用户名等，也支持自定义正则解析
	mutate: 修改字段名，删除，更新等操作，转换字段类型等
	drop: 删除某些时间，如debug
	clone: 拷贝一份事件副本，用来添加或删除字段
	geoip: 通过ip获取地理位置信息
	ruby: 支持原生的ruby代码，操作事件，实现强大的其他功能

**ouput常用的输出**
	elasticsearch: 比较常用
	file: 写入文件
	redis: 写入队列
	hdfs: 写入HDFS，需要插件支持
	zabbix: [zabbix监控](https://www.elastic.co/guide/en/logstash/current/plugins-outputs-zabbix.html)
	mongodb: 写入mongodb数据库

**logstash插件支持数据类型**
```java
数组: path => ["a","b"]
布尔: ssl_enable => true
字节: 
	my_bytes => "1113" #1113 bytes
	my_bytes => "10MiB" # 10485760 bytes
	my_bytes => "100kib" #102400 bytes
	my_bytes => "180mb" #180000000 bytes
编码: codec => "json"
哈希表: 
	match => {
	"k1" => "v1"
	"k2" => "v2"
	"k3" => "v3"
	}
数值: port => 33
密码: pwd => "password"
路径: path => "/tmp/logstash"
字符串：name => "hello world"
注释: 
	input{
	#号开头，与shell脚本注释一样
	}
```

在线grok正则的地址: [http://grokdebug.herokuapp.com](http://grokdebug.herokuapp.com)

logstash基础正则地址: [https://github.com/elastic/logstash/blob/v1.4.2/patterns/grok-patterns](https://github.com/elastic/logstash/blob/v1.4.2/patterns/grok-patterns)

**logstash安装**
```
rpm --import http://packages.elasticsearch.org/GPG-KEY-elasticsearch
cat > /etc/yum.repos.d/logstash.repo << EOF
[logstash-5.0]
name=logstash repository for 5.0.x packages
baseurl=http://packages.elasticsearch.org/logstash/5.0/centos
gpgcheck=1
gpgkey=http://packages.elasticsearch.org/GPG-KEY-elasticsearch
enabled=1
EOF
yum clean all
yum install logstash
```
![logstash-01](https://aaron-13.github.io/images/logstash-01.png)

Logstash就像管道符一样
数据在线程之间以事件的形式流转，不要叫行，因为logstash可以处理多行事件。

Logstash会给事件添加一些额外的信息，最重要的是@timestamp，用来标记事件的发生时间。因为这个字段涉及到Logstash的内部流转，所以必须是一个joda对象，如果尝试给一个字符串字段重命名为@timestamp，Logstash会直接报错。使用filters/date插件来管理这个特殊字段。
此外，大多数情况，还可以见到另外几个:
- **host**标记事件发生在哪里
- **type**标记事件的唯一类型
- **tags**标记事件的某方面属性。这是一个数组，一个事件可以有多个标签

**每个logstash过滤插件，都会有四个方法叫add_tag，remove_tag，add_field和remove_field。他们在插件过滤匹配成功时生效。


### 配置语法
Logstash通常习惯使用shipper，broker和indexer来描述数据流中不同的进程各自的角色
![logstash-02](https://aaron-13.github.io/images/logstash-02.png)

### 语法
Logstash设计了自己的DSL--包括有`区域，注释，数据类型(布尔值，字符串，数值，数组，哈希)，条件判断，字段引用等`

### 区段
Logstash用{}来定义区域。区域内可以包括插件区域定义，可以在一个区域内定义多个插件。插件区域内则可以定义键值对设置
```
input{
	stdin{}
	syslog{}
}
```

### 数据类型
Logstash支持少量的数据值类型

+ bool		
  debug => true
+ string	
  host => "hostname"
+ number
  port => 54
+ array		
  match => ["datetime","UNIX","ISO8601"]
+ hash		
	option{
		key1 => "value1",
		key2 => "value2"
	}

### 字段引用(field reference)
字段是`Logstash::Event`对象的属性。事件就像哈希一样，字段就像一个键值对
如果想要在Logstash配置中使用字段的值，只需要把字段的名字写在中括号[]里，即字段引用
对于**嵌套字段**(多维哈希表/哈希的哈希)，每层的字段名都写在[]中，如`[geoip][location][0]`
*TIPS*: logstash的数组也支持倒序下标,`[geoip][location][-1]`可以获取数组最后一个元素的值

Logstash还支持变量内插，在字符串里使用字段引用的方法:
`the longitude is %{[geoip][location][0]}`

### 条件判断(condition)
Logstash从1.3开始支持条件判断和表达式。
表达式支持下面这些操作符:
+ ==,!=,<,>,<=,>=
+ =~(匹配正则)，!~(不匹配正则)
+ in(包含)，not in(不包含)
+ and，or，nand(非与)，xor(非或)
+ ()(复合表达式)，!()(对复合表达式结果取反)

```
if "_grokparsefailure" not in [tags] {
} else if [status] !~ /^2\d\d/ or ([url] == "/noc.gif" nand [geoip][city] != "beijing") {
} else {
} 
```

### 命令行参数
Logstash提供了一个shell脚本叫logstash方便快速运行。支持以下参数:

+ -e 执行
`bin/logstash -e ''`其默认参数是: 

```
input{
	stdin{}
}
output {
	stdout{}
}
```

+ --config或-f 文件
`bin/logstash -f agent.conf`
logstash会自动读取/etc/logstash.d/目录下的*.conf的文本文件。

	**注意**: logstash列出目录下所有文件时，是按字母排序的。而logstash配置段的filter和output都是顺序执行，所以顺序非常重要

+ --configtest或-t 测试
用来测试Logstash读取到的配置文件语法是否能正常解析。Logstash配置语法是用grammar.treetop定义的。

+ --log或-l 日志
Logstash默认输出日志到标准错误。`bin/logstash -l logs/logstash.log`

+ --pipeline-workers或-w
运行filter和output的pipeline线程数量。默认是CPU核数

+ --pipeline-batch-size或-b
每个Logstash pipeline线程，在执行具体的filter和output函数之前，最多能累积的日志条数。默认是125条。越大性能越好，同样也会消耗越多的JVM内存

+ --pipeline-batch-delay或-u
每个Logstash pipiline线程，在打包批量日志的时候，最多等待几毫秒，默认5ms

+ --pluginpath或-P 插件
`bin/logstash -P /path/to/plugin` 加载

+ --verbose
输出一定的调试日志

+ --debug
输出更多的调试的日志


### 设置文件
从Logstash5.0开始，新增了$LS_HOME/config/logstash.yml文件，可以将所有的命令行参数都通过YAML文件方式设置。同时为了反映命令行配置参数的层级关系，参数也都改用.而不是-了。
```YAML
pipeline:
  workers: 2
  batch:
	size: 100
	delay: 5
```

## plugin的安装
从logstash1.5.0版开始，logstash将所有的插件都独立拆分成gem包。每个插件都可以独立更新。

**plugin用法说明**

```
Useage:
	bin/logstash-plugin [options] SUBCOMMAND [ARG]...

Parameters:
	SUBCOMMAND		subcommand
	[ARG] ... 		subcommand arguments

Subcommands:
	install			Install a plugin
	uninstall		Uninstall a plugin
	update			Update a plugin
	list			List all installed plugins

Options:
	-h,--help		print help
```

`bin/logstash-plugin list`查看本机有多少插件可用。(在vendor/bundle/jruby/1.9/gem/目录下)




**本地插件安装**
`bin/logstash-plugin`不单可以通过rubygems平台安装插件，还可以读取本地路径的gem文件。这对自定义插件或者无外接网络的环境非常有效:
`bin/logstash-plugin install /path/to/logstash-filter-crash.gem`



## logstash运行方式
------

**标准的service方式**
RPM安装，配置文件放在/etc/logstash/conf.d目录下，然后运行service logstash start命令即可

**最基础的nohup方式**
`nohup bin/logstash -f config/*.conf &`

**SCREEN方式**
通过screen命令创建的环境下运行的终端命令，其父进程不是sshd登录的会话，而是screen。这样就可以避免用户退出进程消失的问题，又随时能重新接管回终端继续操作。
创建独立的screen命令如下:
`screen -dmS elkscreen_1`
接管连入创建的elkscreen_1命令如下:
`screen -r elkscreen_1`
在此终端下运行logstash之后，不要按`ctrl+c`退出，按`ctrl+a+d`。


**最推荐的daemontools方式**
daemontools是一类软件名称，配置略复杂，包括但不限于python实现的supervisord，perl实现的ubic，ruby实现的god等
`yum install supervisord -y --enablerepo=eple`
在/etc/supervisord.conf配置文件中添加内容，定义要启动的程序:
```
[program:elkpro_1]
environment=LS_HEAP_SIZE=5000m
directory=/opt/logstash
command=/opt/logstash/bin/logstash -f /etc/logstash/pro1.conf -w 10 -l /var/log/logstash/pro1.log
[program:elkpro_2]
environment=LS_HEAP_SIZE=5000m
directory=/opt/logstash
command=/opt/logstash/bin/logstash -f /etc/logstash/pro2.conf -w 10 -l /var/log/logstash/pro2.log
```

然后启动`service supervisord start`即可
logstash会以supervisord子进程的身份运行，还可以使用supervisorctl命令，单独控制一系列logstash子进程中某一个进程的起停操作
`supervisorctl stop elkpro_2`
