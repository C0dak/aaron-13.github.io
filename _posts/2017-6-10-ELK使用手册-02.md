# ELK使用手册-02

---

### 插件配置

#### input配置

**读取文件(file)**
Logstash使用一个名叫FileWatch的Ruby Gem库来监听文件变化。这个库支持glob展开文件路径，而且会记录一个叫.sincedb的数据库文件来跟踪被监听的日志文件的当前读取位置。
sincedb文件中会记录每个被监听的文件的inode,major number,minor number和pos。

**配置示例**
```
input {
	file {
		path => ["/var/log/*.log","/var/log/message"]
		type => "system"
		start_position => "begining"
	}
}
```

**解释**

有一些配置项可以用来指定FileWatch库的行为:

+ discover_interval
logstash每隔多久去检查一次被监听的path下是否有新文件。默认是15秒

+ exclude
不想被监听中的文件可以排除，和path一样支持glob展开

+ close_older
一个已经监听中的文件，如果超过这个值的时间内没有更新内容，就关闭监听它的文件句柄，默认是3600秒

+ igonre_older
在每次检查文件列表的时候，如果一个文件的最后修改时间超过了这个值，就忽略这个文件。默认是3600秒

+ sincedb_path
如果不想用默认的$HOME/.sincedb，可以通过这个配置定义sincedb文件到其他位置

+ sincedb_write_interval
logstash每隔多久写一次sincedb文件。默认是15秒

+ stat_interval
logstash每隔多久检查一次被监听文件状态是否有更新，默认是1秒

+ start_position
logstash从什么位置开始读取文件数据。默认是结束位置。如果要导入原有数据，把这个设定为"beginning",logstash会从头开始读取，类似`less +F`的形式运行

**注意**
1. 通常要导入原有数据进Elasticsearch的话，还需要filter/date插件来修改默认的@timestamp字段值

2. FileWatch只支持文件的**绝对路径**，而且不会自动递归目录。所以有需要的话，用数组方式写明具体文件

3. LogStash::Inputs::File 只是在进程运行的注册阶段初始化一个FileWatch对象，所以它不能支持类似fluentd那样的`path => "/path/to/%{+yyyy/MM/dd/hh}.log"`写法。只能写成`/path/to/*/*/*/*.log`。FileWatch模块提供了一个稍微简单一点的写法:`/path/to/**/*.log`，用**来缩写表示递归全部子目录

4. start_position仅在该文件从未被见听过的时候起作用。如果sincedb文件中已经有这个文件的inode记录，那么logstash依然会从记录过的pos开始读取数据。所以重复测试的时候，需要删除sincedb文件。(另一种方式:将sincedb_path定义为/dev/null，则每次重启自动从头开始读)

5. 因为windows平台没有inode概念，推荐使用nxlog作为收集端

------

#### 标准输入(stdin)

**配置示例
```
input {
	stdin {
		add_field => {"key" => "value"}
		codec => "plain"
		tags => ["add"]
		type => "std"
	}
}
```

![logstash-03](https://aaron-13.github.io/images/logstash-03.png)
![logstash-04](https://aaron-13.github.ip/images/logstash-04.png)

**解析**
type和tags是logstash事件中两个特殊的字段。在输入区段中通过type来标记事件类型，而tags则是在数据处理过程中，由具体的插件来添加或者删除的。

```
input {
	stdin {
		type => "web"
	}
}
filter {
	if [type] == "web" {
		grok {
			match => ["message",%{COMBINEDAPACHELOG}]
		}
	}
}
output {
	if "_grokparsefailure" in [tags] {
		nagios_nsca {
			nagios_status => "1"
		} 
	} else {
		elasticsearch {
		}
	}
}
```


#### 读取syslog数据

配置示例
```
input {
	syslog {
		port => "514"
	}
}
```

Logstash是用UDPSocket，TCPServer和LogStash::Filters::Grok来实现LogStash::Inputs::Syslog的。

```
input {
	tcp {
		port => "5514"
	}
}
filter {
	grok {
		match => ["message","%{SYSLOGLINE}"]
	}
	syslog_pri{ }
}
```

**建议使用LogStash::Inputs::Syslog的时候走TCP协议来传输数据**
UDP监听器只用了一个线程，而TCP监听器会在接收每个连接的时候都启动新的线程来处理后续步骤

**查看UDP缓冲区大小**
`cat /proc/sys/net/core/rmem_max` 最大缓存空间
`cat /proc/sys/net/core/rmem_default`  默认使用的缓存空间
`sysctl -a | grep rmem_max/default`

建议使用LogStash::Inputs::TCP和LogStash::Filters::Grok配合实现同样的syslog功能
虽然在使用TCPServer的时候可以采用多线程处理数据的接收，但同一客户端的数据处理中，grok和date是一直在该线程中完成的，会导致处理性能下降。将两步拆分到filters阶段后，对该阶段插件单独设置多线程运行，能提高处理性能。


#### 读取网络数据(TCP)
LogStash有自己的TCP/UDP插件，也可在测试环境使用
**LogStash::Inputs::TCP用Ruby的socket和openssl库实现了高级的SSL功能，但LogStash本身只能在SizedQueue中缓存20个时间。建议生产环境中换用其他消息队列

**配置示例**
```
input {
	tcp {
		port => 8888
		mode => "server"
		ssl_enable => false
	}
}
```

**常见场景**
LogStash::Inputs::TCP最常见的用法是配合nc命令导入旧数据。在启动logstash进程后，在另一终端运行如下命令即可导入数据:

` nc 127.0.0.1 8888 < olddata`

这种做法比用LogStash::Inputs::File好，因为当nc命令结束，我们就知道数据导入完毕了。而用input/file方式，logstash进程还会一直等待新数据输入被监听的文件，不能直接看出是否完成任务。



#### 编码插件(codec)

Codec是logstash从1.3.0开始引入的概念。此前logstash只支持纯文本形式的输入，然后用过滤器处理。
LogStash是一个`input | decode | filter | encode | output`的数据流。codec就是用来decode和encode事件的



#### 采用json编码

一种降低logstash过滤器的CPU负载消耗的做法: **直接输入预定义好的JSON数据，这样就可以省略掉filter/grok配置**

**配置示例**
```
logformat json '{"@timestamp":"$time_iso8601",'
	'"@version":"1",'
	'"host":"$server_addr",'
	'"client":"$remote_addr",'
	'"size":$body_bytes_sent,'
	'"responsetime":$request_time,'
	'"domain":"$host",'
	'"url":"$uri",'
	'"status":"$status"}';
access_log /var/log/nginx/access.log_json json;
```

**注意**：在`$request_time`和`$body_bytes_sent`变量两头没有双引号，这两个数据在JSON里应该是数值类型


重启nginx应用，然后修改input/file区段配置成下面这样:

```
input {
	file {
		path => "/var/log/nginx/access.log_json"
		codec => "json"
	}
}
```
![json-01](https://aaron-13.github.io/images/json-01.png)
![json-02](https://aaron-13.github.ip/images/json-02.png)


如果Nignx作为一个代理服务器运行的话，访问日志有些变量，如`$upstream_response_time`,可能不会一直是数字，也可能是一个"-"字符串，这会导致logstash对输入数据验证报异常

有两个方法解决这个问题:
1. 用sed在输入之前先替换 - 成 0
运行logstash进程时不再读取文件而是标准输入，这样命令就变成了下面这个样子

```
tail -F /var/log/nginx/proxy_access.log_json \ 
	| sed 's/upstreamtime":-/upsteamtime":0/' \
	| /usr/local/logstash/bin/logstash -f /usr/local/logstash/etc/proxylog.conf
```

2. 日志格式中统一记录为字符串格式(即都带上双引号"),然后再在logstash中用filter/mutate插件来变更应该是数值类型的字符字段的值得类型


**合并多行数据(Multiline)**

有时候，应用程序调试日志会包含非常丰富的内容，为一个事件打印出很多行内容。这种日志通常都很难通过命令行解析的方式做分析。
Logstash正为此准备codec/multiline插件

**TIPS: multiline插件也可以用于其他类型的堆栈式信息，比如Linux内核日志**


**配置示例**
```
input {
	stdin {
		codec => multiline {
			pattern => "^\["
			negate => true
			what => "previous"
		}
	}
}
```

**解释**
这个插件原理很简单，就是把当前行的数据添加到前面一行后面，知道新进的当前行匹配"^\["正则为止


**Log4j的另一种方案**
使用codec/multiline确实是一种办法。不过，logstash还提供了另一种处理log4j的方式:`input/log4j`。与codec/multiline不同，这个插件是直接调用了`org.apache.log4j.spi.LoggingEvent`处理TCP端口节后的数据



####collectd问题

collectd是一个守护(deamon)进程，用来收集系统性能和提供各种存储方式来存储不同值的机制。它会在系统运行和存储信息时周期性的统计系统的相关统计信息。利用这些信息有助于查找当前系统性能瓶颈(如作为性能分析`performance analysis`)和预测系统未来的load(如能力部署`capacity planning`)等


**collectd的安装**

官方的一个软件仓库:[https://pkg.ci.collectd.org](https://pkg.ci.collectd.org) 构建有rpm，deb的软件包


```
echo "deb http://pkg.ci.collectd.org/deb $(lsb_release -sc) collectd-5.5" | sudo tee /etc/apt/sources.list.d/collectd.list
curl -s https://pkg.ci.collectd.org/pubkey.asc | sudo apt-key add -
sudo apt-get update && sudo apt-get install -y collectd
```

------

```
cat > /etc/yum.repos.d/collectd.repo <<EOF
[collectd-5.5]
name=collectd-5.5
baseurl=http://pkg.ci.collectd.org/rpm/collectd-5.5/epel-\$releasever-\$basearch/
gpgcheck=1
gpgkey=http://pkg.ci.collectd.org/pubkey.asc
EOF

yum install -y collectd
# 其他collectd插件需要安装对应的collectd-xxxx软件包
```


**源码安装collectd**

```
# collectd目前维护3个版本, 5.4, 5.5, 5.6。根据自己需要选择版本
wget http://collectd.org/files/collectd-5.4.1.tar.gz
tar zxvf collectd-5.4.1.tar.gz
cd collectd-5.4.1
./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var --libdir=/usr/lib --mandir=/usr/share/man --enable-all-plugins
make && make install
```

**解决依赖关系(RH系列)**

```
rpm -ivh "http://dl.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm"
yum -y install libcurl libcurl-devel rrdtool rrdtool-devel perl-rrdtool rrdtool-perl libgcrypt-devel gcc make gcc-c++ liboping liboping-devel perl-CPAN net-snmp net-snmp-devel
```

**安装启动脚本**

```
cp contrib/redhat/init.d-collectd /etc/init.d/collectd
chmod +x /etc/init.d/collectd
```

**启动collectd**

```
service collectd start
```

logstash配置文件中的配置:
```
input {
    udp {
        port => 25826
        buffer_size => 1452
        workers => 3          # Default is 2
        queue_size => 30000   # Default is 2000
        codec => collectd { }
        type => "collectd"
    }
}
```

![collectd-01](https://aaron-13.github.io/images/collectd-01.png)

**配置了network插件，要记得启用network插件**


**参考资料**
+ collectd支持收集的数据类型: [http://git.verplant.org/?p=collectd.git;a=blob;hb=master;f=README](http://git.verplant.org/?p=collectd.git;a=blob;hb=master;f=README)

+ collectd收集各数据类型的配置参考资料: [http://collectd.org/documentation/manpages/collectd.conf.5.shtml](http://collectd.org/documentation/manpages/collectd.conf.5.shtml)

+ collectd简单配置文件示例: [https://gist.github.com/untergeek/ab85cb86a9bf39f1fc6d](https://gist.github.com/untergeek/ab85cb86a9bf39f1fc6d)



#### NetFlow
NetFlow是一种数据交换方式。NetFlow提供网络流量的会话级视图，记录下每个TCP/IP事务的信息。不能像tcpdump那样提供网络流量的完整记录，但汇集起来，更加易于管理和读取。**NetFlow由Cisco创造**

**工作原理**: NetFlow利用标准的交换模式处理数据流的第一个IP包数据，生成NetFlow缓存，随后同样的数据基于缓存信息在同一个数据流中进行传输，不再匹配相关的访问控制等策略，NetFlow缓存同时包含了随后数据流的统计信息。NetFlow有两个核心的组件:NetFlow缓存，存储IP流信息;NetFlow的数据导出或传输机制，NetFlow利用此机制将数据发送到网络管理采集器。

**概念**: 一个NetFlow流定义为在一个源IP地址和目的IP地址间传输的单向数据包流，且所有数据包具有共同的传输层源，目的端口号。

```
input {
	udp {
		port => 9995
		codec => netflow {
			definitions => /home/logstash/lib/.../netflow/netflow.yml
			version => [5]
			}
		}
	}

output {
	stdout { codec => rubydebug }
		if ( [host] = ~ "127\.0\.0\.1" ) {
			elasticsearch {
				index => "logstash_netflow5-%{+YYYY.MM.dd}"
				host => "localhost"
			}
		} else {
			elasticsearch {
				index => "logstash-%{+YYYY.MM.dd}"
				host => "localhost"
			}
		}
	}
```





