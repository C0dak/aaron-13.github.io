# pipeline

------

LogStash对日志的处理，从input到output，就像在Linux命令行上的管道操作一样。事实上，在Logstash中，对此有一个专门的名词，叫Pipeline。

Pipeline的代码加载路径:

```
bin/logstash -> logstash-core/lib/logstash/runner.rb -> logstash-core/lib/logstash/agent.rb -> logstash-core/lib/logstash/pipeline.rb
```

Logstash从2.2开始对pipeline做了大幅重构，目前的5.0版`pipeline.rb`，可以归纳为如下代码:

```
    # 初始化阶段
    @config = grammar.parse(configstr)
    code = @config.compile
    eval(code)

    queue = LogStash::Util::WrappedSynchronousQueue.new
    @input_queue_client = queue.write_client
    @filter_queue_client = queue.read_client

    # 启动指标计数器
    @filter_queue_client.set_events_metric()
    @filter_queue_client.set_pipeline_metric()

    # 运行
    LogStash::Util.set_thread_name("[#{pipeline_id}]-pipeline-manager")

    # 启动输入插件
    @inputs.each do |input|
        input.register
        @input_threads << Thread.new do
            LogStash::Util::set_thread_name("[#{pipeline_id}]<#{input.class.config_name}")
            plugin.run(@input_queue)
        end
    end

    @outputs.each {|o| o.register }
    @filters.each {|f| f.register }

    max_inflight = batch_size * pipeline_workers
    pipeline_workers.times do |t|
        @worker_threads << Thread.new do
            LogStash::Util.set_thread_name("[#{pipeline_id}]>worker#{t}")
            @filter_queue_client.set_batch_dimensions(batch_size, batch_delay)
            while true
                batch = @filter_queue_client.take_batch

                # 开始过滤
                batch.each do |event|
                    filter_func(event).each do |e|
                        batch.merge(e)
                    end
                end
                # 计数
                @filter_queue_client.add_filtered_metrics(batch)

                # 开始输出
                output_events_map = Hash.new { |h,k|  h[k] = [] }
                batch.each do |event|
                    output_func(event).each do |output|
                        output_events_map[output].push(event)
                    end
                end
                output_events_map.each do |output, events|
                    output.multi_receive(events)
                end
                @filter_queue_client.add_output_metrics(batch)

                # 释放
                @filter_queue_client.close_batch(batch)
            end
        end
    end

    # 运行
    @input_threads.each(&:join)
```

该缩略版可以了解到一个重要信息: queue是一个固定大小为0的多线程同步队列。filter和output插件，则在相同的`pipeline_worker`线程中运行，该线程每次批量获取数据，也批量传递给filter和output插件。
由于input到filter之间有唯一的队列，任意一个filter或者output发生堵塞，都会一直堵塞到最前端的接收，这也是logstash-input-heartbeat的理论基础。



## LogStash中Event的生成

------

Logstash从1.5开始，把各个plugin拆分成了单独的gem，主代码只留下几个`base.rb`类。要了解详细情况，需要阅读一个实际跑数据的插件，比如:
`vendor/bundle/jruby/1.9/gems/logstash-input-stdin-3.2.0/lib/logstash/inputs/stdin.rb`

```
@host = Socket.gethostname
while !stop?
	if data = stdin_read
	@codec.decode(data) do |event|
		decorate(event)
		event.set("host",@host) if !event.include?("host")
		queue << event
	end
end
```

函数：@codec.decode(line)和decorate(event)

@codec在`stdin.rb`中默认为line
`vendor/bundle/jruby/1.9/gem/logstash-codec-line-3.0.2/lib/logstash/codecs/line.rb`相关部分:

```
  def register
    require "logstash/util/buftok"
    @buffer = FileWatch::BufferedTokenizer.new(@delimiter)
    @converter = LogStash::Util::Charset.new(@charset)
    @converter.logger = @logger
  end
  public
  def decode(data)
    @buffer.extract(data).each do |line|
      yield LogStash::Event.new("message" => @converter.convert(line))
    end
  end # def decode
```

在这个`@codec.decode(data)`里，生成了`LogStash::Event`对象。其他除了message字段之外的哪些数据，如何来的？在5.0之前，可以通过`lib/logstash/event.rb`看到相关属性的定义和操作。5.0之后，LogStash为了提高性能，对Event部分采用Java语言进行了重构，在`logstash-core-event-java/lib/logstash/event.rb`中只能看到通过JRuby的专属require指令加载jar的语句。

想要了解Logstash::Event的实际定义，需要去git仓库下载，阅读Java源码，也可以直接通过网页阅读: [https://github.com/elastic/logstash/blob/master/logstash-core-event-java/src/main/java/org/logstash/Event.java](https://github.com/elastic/logstash/blob/master/logstash-core-event-java/src/main/java/org/logstash/Event.java)

```
public static final String METADATA = "@metadata";
public static final String METADATA_BRACKETS = "[" + METADATA + "]";
public static final String TIMESTAMP = "@timestamp";
public static final String TIMESTAMP_FAILURE_TAG = "_timestampparsefailure";
public static final String TIMESTAMP_FAILURE_FIELD = "_@timestamp";
public static final String VERSION = "@version";
public static final String VERSION_ONE = "1";

public Event()
    {
        this.metadata = new HashMap<String, Object>();
        this.data = new HashMap<String, Object>();
        this.data.put(VERSION, VERSION_ONE);
        this.cancelled = false;
        this.timestamp = new Timestamp();
        this.data.put(TIMESTAMP, this.timestamp);
        this.accessors = new Accessors(this.data);
        this.metadata_accessors = new Accessors(this.metadata);
    }
```



## 自定义一个插件

------

在运行logstash的时候，可以通过`--pluginpath`参数来加载自定义的插件

**插件格式**

一个标准的logstash输入插件格式如下:

```
require 'logstash/namespace'
require 'logstash/inputs/base'
class LogStash::Inputs::MyPlugin < LogStash::Inputs::Base
	config_name 'myplugin'
	default :codec, "line"
	config :myoption_key, :validate => :string, :default => 'myoption_value'
	public def register
	end
	public def run(queue)
	end
end
```

其中大多数语句在过滤器和输出阶段是共有的。

+ config_name用来定义该插件写在logstash配置文件中的名字

+ config可以定义很多个，即该插件在logstash配置文件中的可配置参数。logstash很温馨的提供了很多验证方法，确保接受的数据是你期望的数据类型

+ register logstash在启动的 时候运行的函数，一些需要常驻内存的数据，可以在这一步先完成。比如对象初始化，filter/ruby插件中的init语句等


**插件的关键方法**

输入插件独有的是 run方法。在run方法中，必须实现一个长期运行的程序(最简单的就是loop指令)。然后在灭此受到数据并处理成`event`,最后要调用`queue << event`语句，一个输入流程算是完成了。

```
require 'logstash/filter/base'
class LogStash::Filters::MyPlugin < LogStash::Filters::Base
	config_name 'myplugin'
	public def register
	end
	public def filter(event)

		filter_matched(event)
	end
end
```

其中，`filter_matched`是在filter函数完成本插件自己的处理逻辑之后一定要调用的。


输出插件是:

```
require 'logstatsh/outputs/base'
class LogStash::Outputs::MyPlugin < LogStash::Outputs::Base
	config_name 'myplugin'
	concurrency :single
	public def register
	end
	public def multi_receive(events)
	end
end
```

和之前版本的差别，处理方法改成了`multi_receive`,而不是`receive`，因为新的pipeline机制是批量传递数据给输出插件的，不过为了兼容过去的插件，`LogStash::Outputs::Base`基类中的`multi_receive`实现继续迭代调用了receive。

另一个是新出现的配置 concurrency，代表着本插件是否threadsafe，并由此取代了过去的workers选项，可选项：single和shared

+ single表示本插件是非线程安全地，必须在各pipeline workers之间同一时刻只有一个运行

+ shared表示本插件是线程安全地，每个pipeline workers之间可以独立运行，这意味着插件作者要自己在multi_receive里调用Mutexes。



推荐阅读
[Extending logstash](http://logstash.net/docs/1.4.2/extending/)

[Plugin Milestones](http://logstash.net/docs/1.4.2/plugin-milestones)



**插件打包**

Logstash从1.5.0-GA开始，对插件规范做了重大变更。放弃了milestone定义，去除了`--pluginpath`命令行参数。统一改成`bin/plugin`管理的rubygem包插件，所以，自定义Logstash插件，还需要打包成gem才能使用。

logstash针对4中插件形态提供了4个示例库，可以按照自己所需克隆使用，比如要写一个logstash-filter-mything插件：

```
git clone https://github.com/logstash-plugins/logstash-filter-example
cd logstash-filter-example
mv logstash-filter-example.gemspec logstash-filter-mything.gemspec
mv lib/logstash/filters/example.rb lib/logstash/filters/mything.rb
mv spec/filters/example_spec.rb spec/filters/mything_spec.rb
```

然后把代码写在`lib/logstash/filters/mything.rb`里即可，然后定义gem打包需要的额外的文件和库依赖。
目录中有两个文件，Gemfile和logstash-filter-mything.gemspec
Gemfile文件就是标准格式，用来运行bundler install时下载rubygems包的，默认情况下，最基础的内容是:

```
source 'https://rubygems.org' # 国内建议改成 'http://ruby.taobao.org'
gemspec
gem "logstash", :github => "elastic/logstash", :branch => "1.5"
```
gemspec文件则是用来定义软件包本身规范，不单限于rubygems

```
Gem::Specification.new do |s|
  s.name = 'logstash-filter-mything'
  s.version         = '1.1.0'
  s.licenses = ['Apache License (2.0)']
  s.summary = "This mything filter is just for Elastic Stack Guide example"
  s.description = "This gem is a logstash plugin required to be installed on top of the Logstash core pipeline using $LS_HOME/bin/logstash-plugin install gemname. This gem is not a stand-alone program"
  s.authors = ["Chenryn"]
  s.email = 'chenlin7@staff.sina.com.cn'
  s.homepage = "http://kibana.logstash.es"
  s.require_paths = ["lib"]

  s.files = `find . -type f ! -wholename '*.svn*'`.split($\)
  s.test_files = s.files.grep(%r{^(test|spec|features)/})

  s.metadata = { "logstash_plugin" => "true", "logstash_group" => "filter" }

  s.requirements << "jar 'org.elasticsearch:elasticsearch', '1.4.0'"
  s.add_runtime_dependency "jar-dependencies"
  s.add_runtime_dependency "logstash-core", '>= 1.4.0', '< 2.0.0'
  s.add_development_dependency 'logstash-devutils'
end
```

其中:

+ s.version就是milestone的替代品，0.1.x相当于是milestone 0；0.9.x相当于milestone 2；1.x.x相当于milestone 3

+ s.file默认写法是`git ls-files`，因为默认是git库，如果采用svn，或者cvs库，都不要紧，只要命令列出的是需要打包进去的文件即可

+ s.metadata是logstash的plugin命令在install的时候会提前verify的特殊信息，要b保留

+ s.add_runtime_dependency是定义插件依赖库的指令，如果有jar包依赖，则额外再添加s.requirements

打包
```
gem build logstash-filter-mything.gemspec
```

运行完就会生成一个logstash-filter-mything-1.1.0.gem软件包，安装使用。



## 读取二进制文件(utmp)

------

Linux系统中有些日志不是以可读文本形式存放文件中，而是以二进制内容存放的。如utmp等。

Files插件在读取二进制文件和文本文件的区别在于没办法一行行处理内容，内容也不是直观可见的，但是在其它处理逻辑是保持一致的，如果多文件支持，断点续传，内容监控等。区别在于bytes的阶段和bytes的转换，在Files的基础上，新增了插件utmp，插件实现了对二进制文件的读取和解析，实现类似于文本文件一行行输出内容，以供Filter做进一步分析。

utmp新增了两个配置项: struct_size和 struct_format

struct_size代表结构体的大小，number类型，struct_format为结构体的内存分布格式，string类型。


```
input {
	utmp {
		path => "/var/log/utmp"
		type => "syslog"
		start_position => "beginning"
		struct_size => 384
		struct
	}
}